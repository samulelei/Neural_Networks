{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers, models, optimizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # making graphics\nimport random  # random generator\nimport shutil # high level operation for files\nimport os # operating system commands\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve # For final result analysis","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input data file locations\n\ntrain_dir = '/kaggle/input/chestxray2017/chest_xray/train/'\nos.listdir(train_dir)\n\ntest_dir = '/kaggle/input/chestxray2017/chest_xray/test/'\nos.listdir(test_dir)","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"['PNEUMONIA', 'NORMAL']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# List all jpeg files in the dataset\n\nnormal_images = [x for x in os.listdir(os.path.join(train_dir, 'NORMAL')) if x.endswith(\".jpeg\")]\npneumonia_images = [x for x in os.listdir(os.path.join(train_dir, 'PNEUMONIA')) if x.endswith(\".jpeg\")]\ntest_normal_images = [x for x in os.listdir(os.path.join(test_dir, 'NORMAL')) if x.endswith(\".jpeg\")]\ntest_pneumonia_images = [x for x in os.listdir(os.path.join(test_dir, 'PNEUMONIA')) if x.endswith(\".jpeg\")]\n\n# Show statistics\n\nN_NORMAL = len(normal_images)\nN_PNEUMONIA = len(pneumonia_images)\nTOTAL = N_NORMAL + N_PNEUMONIA\n\nN_TEST_NORMAL = len(test_normal_images)\nN_TEST_PNEUMONIA = len(test_pneumonia_images)\nTEST_TOTAL =  N_TEST_NORMAL + N_TEST_PNEUMONIA\n\nprint('Training images:')\nprint(f'{N_NORMAL:5d} normal cases')\nprint(f'{N_PNEUMONIA:5d} pneumonia cases')\nprint(f'{TOTAL:5d} total images\\n')\n\nprint('Test images:')\nprint(f'{N_TEST_NORMAL:5d} normal cases')\nprint(f'{N_TEST_PNEUMONIA:5d} pneumonia cases')\nprint(f'{TEST_TOTAL:5d} total test images')","execution_count":4,"outputs":[{"output_type":"stream","text":"Training images:\n 1349 normal cases\n 3883 pneumonia cases\n 5232 total images\n\nTest images:\n  234 normal cases\n  390 pneumonia cases\n  624 total test images\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Directories for train, validation and test data\n\ncnn_train_dir = './train'\ncnn_valid_dir = './validation'\ncnn_test_dir = './test'\nall_dirs = [cnn_train_dir, cnn_valid_dir, cnn_test_dir]\ntry:\n    for d in all_dirs:\n        os.mkdir(d)\n        os.mkdir(os.path.join(d, 'NORMAL'))\n        os.mkdir(os.path.join(d, 'PNEUMONIA'))\nexcept:\n    pass\nprint ('Training directory = ', cnn_train_dir)\nprint (os.listdir(cnn_train_dir))\nprint ('Validation directory = ', cnn_valid_dir)\nprint (os.listdir(cnn_valid_dir))\nprint ('Test directory = ', cnn_test_dir)\nprint (os.listdir(cnn_test_dir))","execution_count":5,"outputs":[{"output_type":"stream","text":"Training directory =  ./train\n['NORMAL', 'PNEUMONIA']\nValidation directory =  ./validation\n['NORMAL', 'PNEUMONIA']\nTest directory =  ./test\n['NORMAL', 'PNEUMONIA']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Shuffle the lists in random order\n\nrandom.shuffle(normal_images)\nrandom.shuffle(pneumonia_images)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Copy labeled images to the pool of images\n\n# Normal validation Images\n\nfor fname in normal_images[:700]:\n    src = os.path.join(train_dir, 'NORMAL', fname)\n    dst = os.path.join(cnn_valid_dir, 'NORMAL', fname)\n    shutil.copyfile(src, dst)\n    \n# Normal training images \n\nfor fname in normal_images[701:]:\n    src = os.path.join(train_dir, 'NORMAL', fname)\n    dst = os.path.join(cnn_train_dir, 'NORMAL', fname)\n    shutil.copyfile(src, dst)\n\n#Normal test images\n\nfor fname in test_normal_images:\n    src = os.path.join(test_dir, 'NORMAL', fname)\n    dst = os.path.join(cnn_test_dir, 'NORMAL', fname)\n    shutil.copyfile(src, dst)\n    \n# Pneunomia validation images\n    \nfor fname in pneumonia_images[:700]:\n    src = os.path.join(train_dir, 'PNEUMONIA', fname)\n    dst = os.path.join(cnn_valid_dir, 'PNEUMONIA', fname)\n    shutil.copyfile(src, dst)\n    \n# Pneunomia training images\n\nfor fname in pneumonia_images[701:]:\n    src = os.path.join(train_dir, 'PNEUMONIA', fname)\n    dst = os.path.join(cnn_train_dir, 'PNEUMONIA', fname)\n    shutil.copyfile(src, dst)\n    \n# Pneumonia test images\n\nfor fname in test_pneumonia_images:\n    src = os.path.join(test_dir, 'PNEUMONIA', fname)\n    dst = os.path.join(cnn_test_dir, 'PNEUMONIA', fname)\n    shutil.copyfile(src, dst)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TS = (150, 150) # Image Target Size\nBS = 16 # Image Batch Size\n\n# Generate two Data Generators for data processing\n\n# https://keras.io/preprocessing/image\n\ntraingen = ImageDataGenerator(rescale=1./255) # All images will be rescaled by 1./255\ndevgen = ImageDataGenerator(rescale=1./255) # All images will be rescaled by 1./255\n\nprint('Training set:')\ntrain_generator = traingen.flow_from_directory(\n    #this is the target directory\n    cnn_train_dir,\n    \n    #All images will be resized to 150x150\n    target_size = TS,\n    \n    #We read images in batches of 16\n    batch_size = BS,\n    \n    #Create binary labels\n    class_mode = 'binary')\n\nprint('Validation set:')\ndev_generator = devgen.flow_from_directory(\n    cnn_valid_dir,\n    target_size = TS,\n    batch_size = BS,\n    shuffle = False,\n    class_mode = 'binary')\n\nprint('Test set:')\ntest_generator = devgen.flow_from_directory(\n    cnn_test_dir,\n    target_size = TS,\n    batch_size = BS,\n    class_mode = 'binary')","execution_count":8,"outputs":[{"output_type":"stream","text":"Training set:\nFound 3830 images belonging to 2 classes.\nValidation set:\nFound 1400 images belonging to 2 classes.\nTest set:\nFound 624 images belonging to 2 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build a simple convolutional neural network (CNN)\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(128, (3, 3), activation = 'relu', input_shape = (150, 150, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(32, (3, 3), activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(16, (3, 3), activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation = 'relu'))\n#model.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(256, activation = 'relu'))\n#model.add(layers.Dropout(0.2))\nmodel.add(layers.Dense(1, activation = 'sigmoid'))\n\nmodel.summary()\n\n# Let's use slower learning rate than the default rate\n# https://keras.io/optimizers\n\nmodel.compile(loss = 'binary_crossentropy', optimizer = optimizers.RMSprop (lr = 1e-4), metrics = ['acc'])","execution_count":9,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 148, 148, 128)     3584      \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 74, 74, 128)       0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 72, 72, 64)        73792     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 34, 34, 32)        18464     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 17, 17, 32)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 15, 15, 16)        4624      \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 7, 7, 16)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 784)               0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               401920    \n_________________________________________________________________\ndense_1 (Dense)              (None, 256)               131328    \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 257       \n=================================================================\nTotal params: 633,969\nTrainable params: 633,969\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Train the network with the training and validation data\n# Reading all batches per epoch (steps_per_epoch = None) using all 4187 images\n# modifying steps_per_epoch = 10 would result in reading only 10 batches per epoch (10x16 = 160 images per epoch)\n\n# https://keras.io/models/sequential/#fit_generator\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch = None,\n    verbose = 1,\n    epochs = 10,\n    validation_data = dev_generator,\n    validation_steps = None)\n\n# save the model\nmodel.save('case_2_run_1.h5')","execution_count":null,"outputs":[{"output_type":"stream","text":"Train for 240 steps, validate for 88 steps\nEpoch 1/10\n240/240 [==============================] - 63s 264ms/step - loss: 0.3740 - acc: 0.8546 - val_loss: 0.3979 - val_acc: 0.7979\nEpoch 2/10\n240/240 [==============================] - 58s 241ms/step - loss: 0.1920 - acc: 0.9230 - val_loss: 0.1659 - val_acc: 0.9329\nEpoch 3/10\n 23/240 [=>............................] - ETA: 33s - loss: 0.1661 - acc: 0.9348","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create variables for history metrics for the fitted model\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(acc))\n\n# Check the accuracy and loss graphs for the training done\n\nplt.plot(epochs, acc, 'bo-', label='Training acc')\nplt.plot(epochs, val_acc, 'r*-', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.grid()\nplt.legend()\n\nplt.figure()\nplt.plot(epochs, loss, 'bo-', label='Training loss')\nplt.plot(epochs, val_loss, 'r*-', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find the labels\n\nlabels = dev_generator.classes\n\n# Predict the results\n\npredicted = model.predict_generator(dev_generator).flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the predicted and true labels\n\nplt.plot (predicted, label = 'Predicted')\nplt.plot (labels, label = 'True value')\nplt.legend()\nplt.xlabel ('Case index')\nplt.grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a confusion matrix and calculate classification report for observations\n\nprint ('Confusion matrix: ')\ncm = confusion_matrix(labels, predicted > 0.5)\nprint(cm)\n\ncr = classification_report(labels, predicted > 0.5, target_names = ['Normal (0)', 'Pneumonia (1)'])\nprint(cr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the ROC curve for further analysis\n\nfpr, tpr, thresholds = roc_curve(labels, predicted, pos_label = 1)\n\n# Show the ROC curve plot\n\nplt.plot (fpr, tpr)\nplt.plot ([0, 1], [0, 1], 'r:')\nplt.xlabel('False positive rate')\nplt.ylabel('True positivite rate')\nplt.title('ROC Curve')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find the best threshold for predictions\n\nplt.plot(thresholds, 1 - fpr, label = 'Specificity')\nplt.plot(thresholds, tpr, label = 'Sensitivity')\nplt.axvline(0.5, color = 'red', linestyle = ':')\nplt.xlim([0, 1])\nplt.title('Threshold value for prediction')\nplt.xlabel('Threshold')\nplt.ylabel('Metrics value')\nplt.legend()\nplt.grid()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test the model accuracy with unseen test data (test_generator)\n\nloss, acc = model.evaluate(test_generator, steps=len(test_generator), verbose=1)\n#loss, acc = model2.evaluate(test_generator, steps=len(test_generator), verbose=1)\n#loss, acc = model3.evaluate(test_generator, steps=len(test_generator), verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**VERY VERY BAD RESULTS :(**\n\nthis mejks me very ankgry"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}